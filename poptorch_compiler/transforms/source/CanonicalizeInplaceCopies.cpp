// Copyright (c) 2022 Graphcore Ltd. All rights reserved.
#include "mlir/IR/MLIRContext.h"
#include "mlir/IR/PatternMatch.h"
#include "llvm/ADT/SmallPtrSet.h"

#include "dialect/PoptorchDialect.hpp"

namespace poptorch_ir {

namespace {

struct CanonicalizeInplaceCopies final : public mlir::OpRewritePattern<copy_> {
  explicit CanonicalizeInplaceCopies(mlir::MLIRContext *context)
      : mlir::OpRewritePattern<copy_>(context) {}

  mlir::LogicalResult
  matchAndRewrite(copy_ op, mlir::PatternRewriter &rewriter) const override {
    // Case 1: (empty_tensor - op - copy_) pattern
    // This pattern is generated by torch ops with output parameters
    // (e.g. avg_pool2d.out). These ops needlessly copy the result
    // of an op into an empty tensor. We can remove both the copy and the
    // empty tensor, and replace all uses of the empty tensor with the
    // result of the op itself.
    if (op.self().getDefiningOp<empty_tensor>() == nullptr) {
      return mlir::failure();
    }

    if (op.self().getType() != op.src().getType()) {
      // Replace the copy by a cast
      auto cast_op = rewriter.create<cast>(
          op.getLoc(), op.src(),
          op.self().getType().cast<mlir::RankedTensorType>().getElementType());
      rewriter.eraseOp(op);
      op.self().replaceAllUsesWith(cast_op.result());
    } else {
      // If we have something of the form:
      // %0 = empty_tensor()
      // %1 = op_foo(%0)        # Don't replace that one: it's before copy_
      // %2 = another_op()
      // poptorch.copy_(%0, %2)
      // copy_to_host(%0)
      //
      // Then we can remove the copy_ and use %2 wherever %0 would have been
      // used after this point.
      //
      // (1) We must be careful to not replace the use of that empty tensor
      // before the copy_ though.
      //
      // (2) This only works if %2 is not modified in place somewhere else:
      //
      // %0 = empty_tensor()
      // %1 = op_foo(%0)        # Don't replace that one: it's before copy_
      // %2 = another_op()
      // poptorch.copy_(%0, %2)
      // add_(%2, %1)           # %2 after this call will be %0 + %1 not just %0
      // copy_to_host(%0)
      //
      if (!op.src().hasOneUse()) {
        // Case (2): the source tensor is used in other places: don't remove the
        // copy_.
        return mlir::failure();
      }

      // Case (1) Identify the uses before the copy_
      llvm::SmallPtrSet<mlir::Operation *, 32> previous_uses;
      // Note: uses are sorted from last to first.
      bool use_before_copy = false;
      for (auto &use : op.self().getUses()) {
        if (use_before_copy) {
          previous_uses.insert(use.getOwner());
        } else {
          if (op.getOperation() == use.getOwner()) {
            // We've found the copy: all the uses after that
            // happened before the copy_
            use_before_copy = true;
          }
        }
      }

      // Replace all the uses except the ones which happened before the copy.
      op.self().replaceAllUsesExcept(op.src(), previous_uses);
      // Then remove the copy_.
      rewriter.eraseOp(op);
    }
    return mlir::success();
  }
};

} // namespace

void copy_::getCanonicalizationPatterns(mlir::OwningRewritePatternList &results,
                                        mlir::MLIRContext *context) {
  results.insert(std::make_unique<CanonicalizeInplaceCopies>(context));
}

} // namespace poptorch_ir
