// Copyright (c) 2021 Graphcore Ltd. All rights reserved.
#include <torch/csrc/jit/ir/ir.h>

#include <vector>

#include "poptorch_logging/Error.hpp"

#include "../../PoptorchSymbols.hpp"
#include "MLIRDispatch.hpp"

/*
 * This file implements the hooks the compiler uses to interface with the
 * PopTorch compiler.
 *
 * The indended operational flow is as follows: Aten operation is encountered.
 *  If it is a directly support MLIR op:
 *    We unpack all the PyTorch arguments into MLIR arguments and call the
 *    autogenerated builder.
 *
 *    These are defined in AtenOpSupport.yml and PoptorchOpSupport.yml
 *
 *  If it is not directly supported in MLIR, then it will go through our normal
 *  canonicalisation process. In this case the dispatch will call another set of
 *  autogenerated functions which unpack the torch::jit::Node in the same way
 *  LowerToPopart does. They use a reduced OP_DEF format which is:
 *    OP_DECL(dynamicadd, dynamicadd,  ARG(INT_VEC,axes) ARG(INT_VEC,sizes))
 *  Unlike MLIR these must specify the arguments (as MLIR doesn't know the JIT
 *  attribute names). However it is still far less than the original lower to
 *  PopART set. Once we have full 1:1 coverage we might want to consider sharing
 *  the same list.
 *
 */

namespace poptorch {

/*
 * The dispatch table maps aten and poptorch operations schemas to their
 * handler in the MLIRDispatch.
 */
void MLIRDispatch::generateDispatchTable() { // NOLINT
  // The generated mapping of PyTorch/Aten -> MLIR functions.
  // Each of functions when passed the PyTorch function arguments will extract
  // and translate all tensors/scalars into an MLIR representation from the
  // given PyTorch and then call the correct MLIR builder function.

  // It is generated by the generate scripts in
  // `poptorch/source/dispatch_tracer/scripts` from AtenOpSupport.yml.
  _direct_dispatch_lookup = {
#include "AtenToMLIRDispatch.inc"
#include "PoptorchToMLIRDispatch.inc"
#include "TorchScatterToMLIRDispatch.inc"
  };
}

} // namespace poptorch
