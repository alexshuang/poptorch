// Copyright (c) 2021 Graphcore Ltd. All rights reserved.
#include <torch/csrc/jit/ir/ir.h>

#include <vector>

#include "../../PoptorchSymbols.hpp"
#include "MlirDispatch.hpp"

/*
 * This file implements the hooks the compiler uses to interface with the
 * PopTorch compiler.
 *
 * The indended operational flow is as follows: Aten operation is encountered.
 *  If it is a directly support MLIR op:
 *    We unpack all the PyTorch arguments into MLIR arguments and call the
 *    autogenerated builder.
 *
 *    These are defined in OpSupport.yml
 *
 *  If it is not directly supported in MLIR, then it will go through our normal
 *  canonicalisation process. In this case the dispatch will call another set of
 *  autogenerated functions which unpack the torch::jit::Node in the same way
 *  LowerToPopart does. They use a reduced OP_DEF format which is:
 *    OP_DECL(dynamicadd, dynamicadd,  ARG(INT_VEC,axes) ARG(INT_VEC,sizes))
 *  Unlike MLIR these must specify the arguments (as MLIR doesn't know the JIT
 *  attribute names). However it is still far less than the original lower to
 *  PopART set. Once we have full 1:1 coverage we might want to consider sharing
 *  the same list.
 *
 * JIT fallback ops are defined in: PopartAPISupportedOps.h.inc
 */

namespace poptorch {

namespace {

// We don't build this on Centos 7.3 TODO(T49566)
#if POPTORCH_BUILD_MLIR_COMPILER

template <typename T> T convert(T t) { return t; }

// String, return const char*. To avoid any ABI boundry issues with std string.
const char *convert(const std::string &s) {
  return s.c_str(); // NOLINT
}

std::vector<const char *> convert(const std::vector<std::string> &s) {
  std::vector<const char *> result;
  std::transform(s.begin(), s.end(), std::back_inserter(result),
                 [](const std::string &str) {
                   return str.c_str(); // NOLINT
                 });
  return result;
}

std::vector<float> convert(const std::vector<double> &v) {
  std::vector<float> result;
  std::transform(v.begin(), v.end(), std::back_inserter(result),
                 [](double d) { return static_cast<float>(d); });
  return result;
}

// We have a seperate list to help us parse the PopART IR Nodes we create as
// part of the normal PopTorch process. This file is located in the compiler
// build directory so if we ever decouple the compiler we would also need to
// move this into a public header.
#include "JitToMlirDispatch.hpp.inc"

#endif

} // namespace

/*
 * The first dispatch table. This is the one which maps from an aten operation
 * onto the above table.
 */
void MLIRDispatch::generateDispatchTable() {
  // The generated mapping of PyTorch/Aten -> MLIR functions.
  // Each of functions when passed the PyTorch function arguments will extract
  // and translate all tensors/scalars into an MLIR representation from the
  // given PyTorch and then call the correct MLIR builder function.

  // It is generated by the generate scripts in
  // `poptorch/source/dispatch_tracer/scripts` from OpSupport.yml.
  _direct_dispatch_lookup = {
#include "AtenToMlirDispatch.inc"
  };

  /*
   * The second dispatch table is used to dispatch from the current TracingV1
   * like PopART/JIT IR nodes we create. This is so we can still support the
   * normal handler path.
   */

// We don't build this on Centos 7.3 TODO(T49566)
#if POPTORCH_BUILD_MLIR_COMPILER
  this->_jit_handlers = {
#define INT_VEC is
#define FLOAT_VEC fs
#define FLOAT f
#define INT i
#define BOOL i
#define STRING s
#define STRING_VEC ss

// Useful NOP macro
#define NONE

// The arguments are processed by extracting the given type using the above
// accessors, the name is converted into "attr::NAME" which is what pytorch
// expects for attribute accessing.
#define ARG(Type, Name)                                                        \
  , convert(node->Type(c10::Symbol::fromQualString("attr::" #Name)))

// Create a function decl with the given call and arguments.
#define OP_DECL(symbolName, function, Args)                                    \
  {symbols::popart::symbolName,                                                \
   [&](torch::jit::Node *node,                                                 \
       const std::vector<poptorch_ir::TensorId> &ids) {                        \
     (void)(node);                                                             \
     return JIT_##function(this->_compiler, ids Args);                         \
   }},

#include "PopartAPISupportedOps.h.inc"
  };

#undef OP_DECL
#undef OP_DECL_NO_RETURN
#undef ARG
#undef NONE
#undef BOOL
#undef STRING
#undef STRING_VEC
#undef INT
#undef FLOAT
#undef FLOAT_VEC
#undef INT_VEC
#endif
}

} // namespace poptorch
